{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e6b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2af7e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page : 1\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 1 scraped\n",
      "scraping page : 2\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 2 scraped\n",
      "scraping page : 3\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 3 scraped\n",
      "scraping page : 4\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 4 scraped\n",
      "scraping page : 5\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 5 scraped\n",
      "scraping page : 6\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 6 scraped\n",
      "scraping page : 7\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 7 scraped\n",
      "scraping page : 8\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 8 scraped\n",
      "scraping page : 9\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 9 scraped\n",
      "scraping page : 10\n",
      "job 0 scraped\n",
      "job 1 scraped\n",
      "job 2 scraped\n",
      "job 3 scraped\n",
      "job 4 scraped\n",
      "job 5 scraped\n",
      "job 6 scraped\n",
      "job 7 scraped\n",
      "job 8 scraped\n",
      "job 9 scraped\n",
      "job 10 scraped\n",
      "job 11 scraped\n",
      "job 12 scraped\n",
      "job 13 scraped\n",
      "job 14 scraped\n",
      "job 15 scraped\n",
      "job 16 scraped\n",
      "job 17 scraped\n",
      "job 18 scraped\n",
      "job 19 scraped\n",
      "job 20 scraped\n",
      "job 21 scraped\n",
      "job 22 scraped\n",
      "job 23 scraped\n",
      "job 24 scraped\n",
      "page 10 scraped\n",
      "scraping process in done\n"
     ]
    }
   ],
   "source": [
    "# scraping aka collecting data \n",
    "start_url =\"https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Data+Analyst&txtLocation=\"\n",
    "paging = \"&sequence={}\"\n",
    "\n",
    "job_titles = []\n",
    "company_names = []\n",
    "experiences = []\n",
    "locations = []\n",
    "descriptions = []\n",
    "skills_sets = []\n",
    "\n",
    "for page in range(1,11):\n",
    "    print(\"scraping page : \"+str(page))\n",
    "    html_text = requests.get(start_url+paging.format(page)).text\n",
    "    bs = BeautifulSoup(html_text,\"lxml\")\n",
    "    jobs = bs.find_all(\"li\", class_ = \"clearfix job-bx wht-shd-bx\")\n",
    "    for i,job in enumerate(jobs):\n",
    "        job_title = job.find(\"header\", class_ = \"clearfix\").h2.text.replace(\"  \",\"\").replace(\"\\n\",\"\")\n",
    "        job_titles.append(job_title)\n",
    "        #print(\"job_title : \"+job_title)\n",
    "        company_name = job.find(\"header\", class_ = \"clearfix\").h3.get_text(strip=True)\n",
    "        company_names.append(company_name)\n",
    "        #print(\"company_name : \"+company_name)\n",
    "        experience = job.find(\"ul\", class_ = \"top-jd-dtl clearfix\").li.get_text(strip=True).replace(\"card_travel\",\"\")\n",
    "        experiences.append(experience)\n",
    "        #print(\"experience : \"+experience)\n",
    "        location = job.find(\"ul\", class_ = \"top-jd-dtl clearfix\").select('li')[1].get_text(strip=True).replace(\"location_on\",\"\")\n",
    "        locations.append(location)\n",
    "        #print(\"location : \"+location)\n",
    "        description = job.find(\"ul\", class_ = \"list-job-dtl clearfix\").li.a[\"href\"]\n",
    "        descriptions.append(description)\n",
    "        #print(\"description : \"+description)\n",
    "        skills = job.find(\"ul\", class_ = \"list-job-dtl clearfix\").select(\"li\")[1].span.text.replace(\"  \",\"\").replace(\"\\n\",\"\")\n",
    "        skills_sets.append(skills)\n",
    "        #print(\"skills : \"+skills)\n",
    "        print(\"job {} scraped\".format(i))\n",
    "    print(\"page {} scraped\".format(page))\n",
    "print(\"scraping process in done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c337e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped data is loaded to scraping data analyst jobs.csv\n"
     ]
    }
   ],
   "source": [
    "#save the data into CSV file for future work\n",
    "dict = {\"job_titles\": job_titles,\"company_names\": company_names,\"experiences\": experiences,\"locations\": locations,\"descriptions_url\": descriptions,\"skills_sets\":skills_sets}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "df.to_csv(\"scraping data analyst jobs.csv\")\n",
    "print(\"scraped data is loaded to scraping data analyst jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3ab7dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>experiences</th>\n",
       "      <th>locations</th>\n",
       "      <th>descriptions_url</th>\n",
       "      <th>skills_sets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>infoanalytica consulting pvt ltd</td>\n",
       "      <td>5 - 8 yrs</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rbusiness rules,sql,Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ikomet Technology Solutions Pvt. Ltd.</td>\n",
       "      <td>0 - 3 yrs</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rmacros,visualization,bi,data analyst,vba\\r\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ACENET TECHNOLOGIES</td>\n",
       "      <td>10 - 15 yrs</td>\n",
       "      <td>Gurgaon,  Delhi,  Delhi/NCR,  Pune,  Bengaluru...</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rbi,dashboards,data analyst,sql,tableau\\r\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Koch Global Business Services</td>\n",
       "      <td>0 - 3 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rfunctional analyst,dashboards,data analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Zealogics LLC.</td>\n",
       "      <td>0 - 3 yrs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>data analysis,gap analysis,data analyst,securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>\\rSenior Data Analyst</td>\n",
       "      <td>PUBLICIS GROUPE</td>\n",
       "      <td>5 - 9 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/senior-da...</td>\n",
       "      <td>\\r\\rsql,hadoop,big data,crm,python,sas,system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>\\rSenior Data Analyst</td>\n",
       "      <td>Epsilon</td>\n",
       "      <td>5 - 9 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/senior-da...</td>\n",
       "      <td>\\r\\rsql,hadoop,big data,crm,python,sas,system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Data Analyst Data and Analytics</td>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>0 - 3 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rmetadata,information technology,data quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>\\rSr. Marketing Data Analyst</td>\n",
       "      <td>AlphaSense</td>\n",
       "      <td>5 - 8 yrs</td>\n",
       "      <td>New York City</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/sr-market...</td>\n",
       "      <td>\\r\\rdigital marketing,customer marketing,campa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>\\rProduct Data Analyst</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>4 - 7 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/product-d...</td>\n",
       "      <td>\\r\\rhive,data mining,sql,testing tools,big dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_titles                          company_names  \\\n",
       "0                       Data Analyst        infoanalytica consulting pvt ltd   \n",
       "1                       Data Analyst   ikomet Technology Solutions Pvt. Ltd.   \n",
       "2                       Data Analyst                     ACENET TECHNOLOGIES   \n",
       "3                       Data Analyst           Koch Global Business Services   \n",
       "4                       Data Analyst                          Zealogics LLC.   \n",
       "..                                ...                                    ...   \n",
       "245            \\rSenior Data Analyst                         PUBLICIS GROUPE   \n",
       "246            \\rSenior Data Analyst                                 Epsilon   \n",
       "247  Data Analyst Data and Analytics          Intel Technology India Pvt Ltd   \n",
       "248     \\rSr. Marketing Data Analyst                              AlphaSense   \n",
       "249           \\rProduct Data Analyst                                  TARGET   \n",
       "\n",
       "     experiences                                          locations  \\\n",
       "0      5 - 8 yrs                                          Ahmedabad   \n",
       "1      0 - 3 yrs                                            Chennai   \n",
       "2    10 - 15 yrs  Gurgaon,  Delhi,  Delhi/NCR,  Pune,  Bengaluru...   \n",
       "3      0 - 3 yrs                              Bengaluru / Bangalore   \n",
       "4      0 - 3 yrs                                                NaN   \n",
       "..           ...                                                ...   \n",
       "245    5 - 9 yrs                              Bengaluru / Bangalore   \n",
       "246    5 - 9 yrs                              Bengaluru / Bangalore   \n",
       "247    0 - 3 yrs                              Bengaluru / Bangalore   \n",
       "248    5 - 8 yrs                                      New York City   \n",
       "249    4 - 7 yrs                              Bengaluru / Bangalore   \n",
       "\n",
       "                                      descriptions_url  \\\n",
       "0    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "1    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "2    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "3    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "4    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "..                                                 ...   \n",
       "245  https://www.timesjobs.com/job-detail/senior-da...   \n",
       "246  https://www.timesjobs.com/job-detail/senior-da...   \n",
       "247  https://www.timesjobs.com/job-detail/data-anal...   \n",
       "248  https://www.timesjobs.com/job-detail/sr-market...   \n",
       "249  https://www.timesjobs.com/job-detail/product-d...   \n",
       "\n",
       "                                           skills_sets  \n",
       "0                  \\r\\rbusiness rules,sql,Data Analyst  \n",
       "1     \\r\\rmacros,visualization,bi,data analyst,vba\\r\\r  \n",
       "2       \\r\\rbi,dashboards,data analyst,sql,tableau\\r\\r  \n",
       "3    \\r\\rfunctional analyst,dashboards,data analyti...  \n",
       "4    data analysis,gap analysis,data analyst,securi...  \n",
       "..                                                 ...  \n",
       "245  \\r\\rsql,hadoop,big data,crm,python,sas,system ...  \n",
       "246  \\r\\rsql,hadoop,big data,crm,python,sas,system ...  \n",
       "247  \\r\\rmetadata,information technology,data quali...  \n",
       "248  \\r\\rdigital marketing,customer marketing,campa...  \n",
       "249  \\r\\rhive,data mining,sql,testing tools,big dat...  \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data for cleaning process aka transforming\n",
    "df = pd.read_csv(\"scraping data analyst jobs.csv\", index_col=[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81c62580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>experiences</th>\n",
       "      <th>locations</th>\n",
       "      <th>descriptions_url</th>\n",
       "      <th>skills_sets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>infoanalytica consulting pvt ltd</td>\n",
       "      <td>5 - 8 yrs</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rbusiness rules,sql,Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ikomet Technology Solutions Pvt. Ltd.</td>\n",
       "      <td>0 - 3 yrs</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rmacros,visualization,bi,data analyst,vba\\r\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ACENET TECHNOLOGIES</td>\n",
       "      <td>10 - 15 yrs</td>\n",
       "      <td>Gurgaon,  Delhi,  Delhi/NCR,  Pune,  Bengaluru...</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rbi,dashboards,data analyst,sql,tableau\\r\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Koch Global Business Services</td>\n",
       "      <td>0 - 3 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rfunctional analyst,dashboards,data analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ADROIT LEARNING AND MANPOWER PVT LTD</td>\n",
       "      <td>7 - 10 yrs</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>data analysis,dashboards,data analyst,sql,tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>\\rSenior Data Analyst</td>\n",
       "      <td>PUBLICIS GROUPE</td>\n",
       "      <td>5 - 9 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/senior-da...</td>\n",
       "      <td>\\r\\rsql,hadoop,big data,crm,python,sas,system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>\\rSenior Data Analyst</td>\n",
       "      <td>Epsilon</td>\n",
       "      <td>5 - 9 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/senior-da...</td>\n",
       "      <td>\\r\\rsql,hadoop,big data,crm,python,sas,system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Data Analyst Data and Analytics</td>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>0 - 3 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/data-anal...</td>\n",
       "      <td>\\r\\rmetadata,information technology,data quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>\\rSr. Marketing Data Analyst</td>\n",
       "      <td>AlphaSense</td>\n",
       "      <td>5 - 8 yrs</td>\n",
       "      <td>New York City</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/sr-market...</td>\n",
       "      <td>\\r\\rdigital marketing,customer marketing,campa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>\\rProduct Data Analyst</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>4 - 7 yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>https://www.timesjobs.com/job-detail/product-d...</td>\n",
       "      <td>\\r\\rhive,data mining,sql,testing tools,big dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_titles                          company_names  \\\n",
       "0                       Data Analyst        infoanalytica consulting pvt ltd   \n",
       "1                       Data Analyst   ikomet Technology Solutions Pvt. Ltd.   \n",
       "2                       Data Analyst                     ACENET TECHNOLOGIES   \n",
       "3                       Data Analyst           Koch Global Business Services   \n",
       "4                       Data Analyst    ADROIT LEARNING AND MANPOWER PVT LTD   \n",
       "..                                ...                                    ...   \n",
       "196            \\rSenior Data Analyst                         PUBLICIS GROUPE   \n",
       "197            \\rSenior Data Analyst                                 Epsilon   \n",
       "198  Data Analyst Data and Analytics          Intel Technology India Pvt Ltd   \n",
       "199     \\rSr. Marketing Data Analyst                              AlphaSense   \n",
       "200           \\rProduct Data Analyst                                  TARGET   \n",
       "\n",
       "     experiences                                          locations  \\\n",
       "0      5 - 8 yrs                                          Ahmedabad   \n",
       "1      0 - 3 yrs                                            Chennai   \n",
       "2    10 - 15 yrs  Gurgaon,  Delhi,  Delhi/NCR,  Pune,  Bengaluru...   \n",
       "3      0 - 3 yrs                              Bengaluru / Bangalore   \n",
       "4     7 - 10 yrs                                          Ahmedabad   \n",
       "..           ...                                                ...   \n",
       "196    5 - 9 yrs                              Bengaluru / Bangalore   \n",
       "197    5 - 9 yrs                              Bengaluru / Bangalore   \n",
       "198    0 - 3 yrs                              Bengaluru / Bangalore   \n",
       "199    5 - 8 yrs                                      New York City   \n",
       "200    4 - 7 yrs                              Bengaluru / Bangalore   \n",
       "\n",
       "                                      descriptions_url  \\\n",
       "0    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "1    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "2    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "3    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "4    https://www.timesjobs.com/job-detail/data-anal...   \n",
       "..                                                 ...   \n",
       "196  https://www.timesjobs.com/job-detail/senior-da...   \n",
       "197  https://www.timesjobs.com/job-detail/senior-da...   \n",
       "198  https://www.timesjobs.com/job-detail/data-anal...   \n",
       "199  https://www.timesjobs.com/job-detail/sr-market...   \n",
       "200  https://www.timesjobs.com/job-detail/product-d...   \n",
       "\n",
       "                                           skills_sets  \n",
       "0                  \\r\\rbusiness rules,sql,Data Analyst  \n",
       "1     \\r\\rmacros,visualization,bi,data analyst,vba\\r\\r  \n",
       "2       \\r\\rbi,dashboards,data analyst,sql,tableau\\r\\r  \n",
       "3    \\r\\rfunctional analyst,dashboards,data analyti...  \n",
       "4    data analysis,dashboards,data analyst,sql,tabl...  \n",
       "..                                                 ...  \n",
       "196  \\r\\rsql,hadoop,big data,crm,python,sas,system ...  \n",
       "197  \\r\\rsql,hadoop,big data,crm,python,sas,system ...  \n",
       "198  \\r\\rmetadata,information technology,data quali...  \n",
       "199  \\r\\rdigital marketing,customer marketing,campa...  \n",
       "200  \\r\\rhive,data mining,sql,testing tools,big dat...  \n",
       "\n",
       "[201 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(\"\", float(\"NaN\"), inplace=True) #removing empty rows\n",
    "df.dropna(inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63b9451f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moaaz\\AppData\\Local\\Temp/ipykernel_22836/1606460935.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['job_titles'] = df['job_titles'].str.replace(r'\\r', '')\n",
      "C:\\Users\\Moaaz\\AppData\\Local\\Temp/ipykernel_22836/1606460935.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['skills_sets'] = df['skills_sets'].str.replace(r'\\r', '')\n"
     ]
    }
   ],
   "source": [
    "# remove irrelevant html text from skills and job & title\n",
    "df['job_titles'] = df['job_titles'].str.replace(r'\\r', '')\n",
    "df['skills_sets'] = df['skills_sets'].str.replace(r'\\r', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68d1b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping skills as a form of bag \n",
    "df['skills_sets'] = df.skills_sets.apply(lambda x: x[:].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5d0d396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiences\n",
       "0 - 1 yrs       8\n",
       "0 - 2 yrs       3\n",
       "0 - 3 yrs      51\n",
       "0 - 9 yrs       1\n",
       "1 - 2 yrs       4\n",
       "1 - 3 yrs       2\n",
       "1 - 4 yrs       5\n",
       "1 - 6 yrs       2\n",
       "10 - 12 yrs     1\n",
       "10 - 15 yrs     1\n",
       "13 - 16 yrs     2\n",
       "2 - 10 yrs      1\n",
       "2 - 3 yrs       4\n",
       "2 - 4 yrs       4\n",
       "2 - 5 yrs      14\n",
       "2 - 6 yrs       2\n",
       "2 - 7 yrs       1\n",
       "2 - 8 yrs       1\n",
       "3 - 10 yrs      1\n",
       "3 - 12 yrs      2\n",
       "3 - 4 yrs       2\n",
       "3 - 5 yrs       9\n",
       "3 - 6 yrs      12\n",
       "3 - 7 yrs       1\n",
       "3 - 8 yrs       2\n",
       "4 - 5 yrs       1\n",
       "4 - 6 yrs       1\n",
       "4 - 7 yrs      12\n",
       "4 - 8 yrs       5\n",
       "4 - 9 yrs       2\n",
       "5 - 10 yrs      1\n",
       "5 - 6 yrs       1\n",
       "5 - 7 yrs       4\n",
       "5 - 8 yrs      19\n",
       "5 - 9 yrs       6\n",
       "6 - 9 yrs       3\n",
       "7 - 10 yrs      3\n",
       "7 - 8 yrs       2\n",
       "7 - 9 yrs       1\n",
       "8 - 11 yrs      2\n",
       "8 - 12 yrs      1\n",
       "9 - 12 yrs      1\n",
       "Name: experiences, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attempt to categorize experience\n",
    "df2 = df.groupby(['experiences'])['experiences'].count()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e71e2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data as ready-to-go dataset of 201 instance\n",
    "df.to_csv(\"data analyst jobs dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563be96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
